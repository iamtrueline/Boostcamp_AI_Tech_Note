# Dropout

- 모델 학습 시 학습 노드를 랜덤하게 탈락시키는 방법. = 무작위 삭제
- 노드 간의 동조현상을 막아 과적합(Overfitting)을 방지할 수 있다.
- 노드 간 동조현상 : 실제 loss에 영향을 미치지 않는 노드 간 협력 상태가 포착되는 현상
- 한 에폭마다 수행되므로 매 에폭에 학습되는 노드가 다르며 이는 앙상블로 표현할 수 있다.
- 앙상블 형태 = 성능 향상을 기대할 수 있다.
