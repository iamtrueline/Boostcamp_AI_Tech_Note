# Gradient Descent (경사 하강법)

- 1차 미분계수를 이용해 함수의 최솟값을 찾아내는 방법.
- 함숫값이 낮아지는 방향으로 전진해서 '하강'법.
- 실제 미분계수가 0인 지점은 단박에 찾긴 어렵고, 단순한 그래프가 아닐 확률이 있기에 점진적인 방법을 쓰는 것.
- 경사하강법 사용의 키 = 적절한 학습률과 학습 횟수.
- 이론적으로 경사하강법은 미분가능하고 볼록(convex)한 함수에 대해선 적절한 학습률과 학습횟수를 선택했을 때 수렴이 보장.
- 비선형회귀 문제에선 목적식이 볼록하지 않을 수 있으므로 수렴이 보장되지 않음.
- 딥러닝을 사용하는 경우 대부분 비선형회귀. 따라서 딥러닝의 경우 업데이트 시 데이터 전체를 활용하는 경사하강법보다 미니배치를 활용하는 확률적 경사하강법이 실증적으로 더 낫다.
