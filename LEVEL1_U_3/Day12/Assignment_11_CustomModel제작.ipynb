{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_11_CustomModel제작.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X_RYE6szDXr"
      },
      "source": [
        "#### PyTorch Release Status (배포 상태)\n",
        "\n",
        "```python\n",
        "😮\n",
        "Stable : 장기적인 확인을 거쳐 일반적인 사용에 문제가 없고 이전 버전과 호환도 유지되는 것으로 판단된 기능.\n",
        "Beta : 아직 확인 중인 기능. Stable에 비해 전반 적용에 대한 안정성 확보가 덜 되었고, 이에 따른 개선이 필요할 수도 있음.\n",
        "Prototype : 피드백과 배포를 위한 초기 단계에 있는 기능.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1EGwkfCxDr7"
      },
      "source": [
        "##### PyTorch의 Linear Algebra\n",
        "\n",
        "``` python\n",
        "torch.linalg\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVq0nUBsq5oB"
      },
      "source": [
        "##### PyTorch의 Matrix Multiplication\n",
        "\n",
        "``` python\n",
        "torch.matmul()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d24oT1bNrHFS"
      },
      "source": [
        "##### PyTorch의 Norm\n",
        "\n",
        "``` python\n",
        "torch.linalg.vector_norm()\n",
        "torch.linalg.matrix_norm()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGptti9wrV6S"
      },
      "source": [
        "##### PyTorch의 기본 구성 요소 Tensor\n",
        "\n",
        "``` python\n",
        "torch.tensor : 데이터를 Tensor 객체로 만들어주는 함수.\n",
        "torch.Tensor : 하나의 데이터 타입을 가지는 다차원 행렬.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WwResrJryLB"
      },
      "source": [
        "##### Add"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e25K7SNsr89R",
        "outputId": "778707af-f25d-4278-df07-56ad89a6ed23"
      },
      "source": [
        "import torch\n",
        "\n",
        "A = torch.Tensor([5])\n",
        "B = torch.Tensor([7])\n",
        "\n",
        "torch.add(A, B)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70K8pb4DtNzM",
        "outputId": "2b2393ba-5564-40db-b2df-f457054c1251"
      },
      "source": [
        "A + B"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVE2CFK0tRIr",
        "outputId": "1e710b11-215c-48e4-bc24-3d849fd76c35"
      },
      "source": [
        "# 피연산자 중 하나라도 tensor가 입력되면 출력값은 tensor.\n",
        "A + 7"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-eAr6c7GEHl"
      },
      "source": [
        "- `+` : torch.add\n",
        "- `-` : torch.sub\n",
        "- `*` : torch.mul\n",
        "- `/` : torch.div"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAnfFG3ht_Qy"
      },
      "source": [
        "##### 사칙연산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVcIb7S6tqwl",
        "outputId": "8e74187b-5ae6-4c01-b155-403c9aa34940"
      },
      "source": [
        "A = torch.Tensor([3])\n",
        "B = torch.Tensor([7])\n",
        "C = torch.Tensor([2])\n",
        "D = torch.Tensor([5])\n",
        "E = torch.Tensor([10])\n",
        "\n",
        "# (3 + 7) * 2 - 5 / 10\n",
        "output = torch.add(A, B)\n",
        "output = torch.mul(output, C)\n",
        "temp = torch.div(D, E)\n",
        "output = torch.sub(output, temp)\n",
        "\n",
        "if output == 19.5:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3zKgnsluDVZ"
      },
      "source": [
        "##### 인덱싱 (Indexing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc95OcS7uK3X",
        "outputId": "3f28660a-c1ad-43e8-ad6a-700fabd11f75"
      },
      "source": [
        "A = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# get [1, 3] using torch.index_select\n",
        "output = A\n",
        "indices = torch.tensor([0])\n",
        "output = torch.index_select(output, 1, indices)\n",
        "output = output.view(1, -1)\n",
        "\n",
        "if torch.all(output == torch.Tensor([1, 3])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKqoBo3AuX6e",
        "outputId": "4e599c24-3ae5-4527-fea6-504548cabff9"
      },
      "source": [
        "A = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# get [1, 3] like python indexing\n",
        "output = A\n",
        "output = output[:, 0]\n",
        "\n",
        "if torch.all(output == torch.Tensor([1, 3])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE7mhekUuhb9"
      },
      "source": [
        "##### 2D tensor에서 대각선 요소 가져오기 - 2D gather"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA43cAsounay",
        "outputId": "4cc1fdec-97bd-407e-ebfd-56d347d10e74"
      },
      "source": [
        "A = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# torch.gather\n",
        "indices = torch.tensor([[0],[1]])\n",
        "output = torch.gather(A, 1, indices)\n",
        "output = output.view(1, -1)\n",
        "\n",
        "if torch.all(output == torch.Tensor([1, 4])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDk3N_YXvMVY"
      },
      "source": [
        "##### 3D tensor에서 대각선 요소 가져오기 - 3D gather"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qskjcN_vUA2",
        "outputId": "f4a335f0-96a8-4a04-dc82-9b358d5c876c"
      },
      "source": [
        "A = torch.Tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "                  [[5, 6],\n",
        "                   [7, 8]]])\n",
        "\n",
        "# torch.gather\n",
        "output = A\n",
        "indices = torch.tensor([[[0],[1]], [[0], [1]]])\n",
        "output = torch.gather(A, 2, indices).squeeze()\n",
        "\n",
        "if torch.all(output == torch.Tensor([[1, 4], [5, 8]])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPMPoF_sxUew"
      },
      "source": [
        "##### 임의의 크기의 3D tensor에서 대각선 요소 가져오기 - 3D gather"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjN0R6qexOKp",
        "outputId": "39d60e8f-e2ac-4e90-be56-7ea4705047c1"
      },
      "source": [
        "# 임의 크기의 3D tensor에서 대각선 요소 가져와 2D로 반환\n",
        "def get_diag_element_3D(A):\n",
        "    output = A\n",
        "    C, H, W = output.shape[0], output.shape[1], output.shape[2]\n",
        "    indices = torch.tensor([i for i in range(min(H,W))]).expand(C,-1).unsqueeze(-1)\n",
        "    output = torch.gather(A, len(A.size()) - 1, indices).squeeze()\n",
        "    return output\n",
        "\n",
        "# 임의 크기 3D tensor\n",
        "C = 1\n",
        "H = 2\n",
        "W = 3\n",
        "\n",
        "A = torch.tensor([i for i in range(1, C*H*W + 1)])\n",
        "A = A.view(C, H, W)\n",
        "\n",
        "print(f\"원본 3D 행렬\\n{A}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"대각선 요소를 모은 2D 행렬\")\n",
        "get_diag_element_3D(A)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 3D 행렬\n",
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "--------------------------------------------------\n",
            "대각선 요소를 모은 2D 행렬\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohFHWN_axy5g",
        "outputId": "a87002a7-1a02-4f3a-98db-1831b1d8b83b"
      },
      "source": [
        "A = torch.tensor([[[1]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1]])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMEvocM0x3G_",
        "outputId": "0a30fe26-3836-4d09-9271-bbc787a79b3b"
      },
      "source": [
        "A = torch.Tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "                  [[5, 6],\n",
        "                   [7, 8]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 4],\n",
        "                                                     [5, 8]])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0zINubWx8HZ",
        "outputId": "62818a6f-7131-42ff-d433-92af5a1c24ee"
      },
      "source": [
        "A = torch.Tensor([[[1, 2, 3],\n",
        "                   [4, 5, 6]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 5]])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk0rKE8qx-py",
        "outputId": "4680de2f-26f4-4380-e14d-112dcb81822b"
      },
      "source": [
        "A = torch.tensor([[[ 1,  2,  3,  4,  5],\n",
        "                   [ 6,  7,  8,  9, 10],\n",
        "                   [11, 12, 13, 14, 15]],\n",
        "          \n",
        "                  [[16, 17, 18, 19, 20],\n",
        "                   [21, 22, 23, 24, 25],\n",
        "                   [26, 27, 28, 29, 30]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  7, 13],\n",
        "                                                     [16, 22, 28]])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lOlJaTLyBwv",
        "outputId": "30cd0626-5f52-4f57-cc6b-7d6a7d49b80c"
      },
      "source": [
        "A = torch.tensor([[[ 1,  2,  3],\n",
        "                   [ 4,  5,  6],\n",
        "                   [ 7,  8,  9],\n",
        "                   [10, 11, 12],\n",
        "                   [13, 14, 15]],\n",
        "        \n",
        "                  [[16, 17, 18],\n",
        "                   [19, 20, 21],\n",
        "                   [22, 23, 24],\n",
        "                   [25, 26, 27],\n",
        "                   [28, 29, 30]],\n",
        "        \n",
        "                  [[31, 32, 33],\n",
        "                   [34, 35, 36],\n",
        "                   [37, 38, 39],\n",
        "                   [40, 41, 42],\n",
        "                   [43, 44, 45]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  5,  9],\n",
        "                                                     [16, 20, 24],\n",
        "                                                     [31, 35, 39]])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLIvrljm_1NI"
      },
      "source": [
        "##### PyTorch 공식 문서 훑기 & 함수 사용 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-MHHbYSAGrW"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 🦆 torch.from_numpy\n",
        "a = np.array([1,2,3])\n",
        "t = torch.from_numpy(a)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S04XXtUAKjh",
        "outputId": "74530008-febd-4c65-b48e-6b012d4cb29a"
      },
      "source": [
        "# 🦆 torch.zeros\n",
        "torch.zeros(2, 3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdUOk47wAO3R",
        "outputId": "b3f8e35b-280d-4453-fb2c-336702f193ff"
      },
      "source": [
        "# 🦆 torch.zeros_like\n",
        "torch.zeros_like(t)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZwG0yI4ARcm",
        "outputId": "572d9ecd-88c8-4f50-a8a2-de8463b8cbd6"
      },
      "source": [
        "# 🦆 torch.chunk\n",
        "t = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "\n",
        "print(torch.chunk(t, 2, 0))\n",
        "print(torch.chunk(t, 2, 1))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[1, 2, 3]]), tensor([[4, 5, 6]]))\n",
            "(tensor([[1, 2],\n",
            "        [4, 5]]), tensor([[3],\n",
            "        [6]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqfn4T5jAdb1",
        "outputId": "0b123f54-9851-49b2-936c-74c2b6708fda"
      },
      "source": [
        "# 🦆 torch.swapdims\n",
        "x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n",
        "torch.swapdims(x, 0, 1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 1],\n",
              "         [4, 5]],\n",
              "\n",
              "        [[2, 3],\n",
              "         [6, 7]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOMXZEH2AkyI",
        "outputId": "bb132d15-d403-4fc2-dea6-e6768305243f"
      },
      "source": [
        "# 🦆 torch.Tensor.scatter_\n",
        "src =torch.arange(1, 11).reshape((2, 5))\n",
        "index = torch.tensor([[0, 1, 2, 0]])\n",
        "torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0, 4, 0],\n",
              "        [0, 2, 0, 0, 0],\n",
              "        [0, 0, 3, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA7GN-zbA80v",
        "outputId": "3656282a-863a-4a9f-a912-9eb9d756b1bd"
      },
      "source": [
        "# 🦆 Random sampling\n",
        "import torch\n",
        "seed = torch.seed()\n",
        "print(seed)\n",
        "manual_seed = torch.manual_seed(seed)\n",
        "print(manual_seed)\n",
        "initial_seed = torch.initial_seed()\n",
        "print(initial_seed)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1333914475654494612\n",
            "<torch._C.Generator object at 0x7f60cff31bb0>\n",
            "1333914475654494612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4B_A_vKBFoN",
        "outputId": "63c710eb-baa0-464a-d83a-4962984303c8"
      },
      "source": [
        "# 🦆 Math operations - Pointwise Ops\n",
        "temp = a = torch.randn(4)\n",
        "print(temp)\n",
        "temp_abs = torch.abs(temp)\n",
        "print(temp_abs)\n",
        "temp_acos = torch.acos(temp)\n",
        "print(temp_acos)\n",
        "temp_acosh = torch.acosh(temp)\n",
        "print(temp_acosh)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9554, 0.9896, 1.9759, 0.0125])\n",
            "tensor([0.9554, 0.9896, 1.9759, 0.0125])\n",
            "tensor([0.2997, 0.1447,    nan, 1.5583])\n",
            "tensor([   nan,    nan, 1.3029,    nan])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF-nCX8DBM2b",
        "outputId": "1acc366f-d372-4c70-e647-8fe2d715c3d1"
      },
      "source": [
        "# 🦆 Math operations - Reduction Ops\n",
        "temp = a = torch.randn(4)\n",
        "print(temp)\n",
        "temp_argmax = torch.argmax(temp)\n",
        "print(temp_argmax)\n",
        "temp_argmin = torch.argmin(temp)\n",
        "print(temp_argmin)\n",
        "temp_all = torch.all(temp)\n",
        "print(temp_all)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4124, -1.0585,  0.0942, -0.5091])\n",
            "tensor(0)\n",
            "tensor(1)\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z88Y7WsHBVDg",
        "outputId": "85f001d4-c1bd-4f00-cf50-b51ddc050edf"
      },
      "source": [
        "# 🦆 Math operations - Comparison Ops\n",
        "temp = a = torch.randn(4)\n",
        "print(temp)\n",
        "temp_allclose = torch.allclose(temp, temp)\n",
        "print(temp_allclose)\n",
        "temp_argsort = torch.argsort(temp)\n",
        "print(temp_argsort)\n",
        "temp_eq = torch.eq(temp, temp)\n",
        "print(temp_eq)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.0435, -0.9395,  2.9141,  1.0029])\n",
            "True\n",
            "tensor([1, 3, 0, 2])\n",
            "tensor([True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN74AZkgBb3f"
      },
      "source": [
        "# 🦆 Math operations - Other Operations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWLDPQnSBqGn",
        "outputId": "6b439399-f6ca-4636-c244-b1ab766a4847"
      },
      "source": [
        "#### einsum\n",
        "\n",
        "# trace\n",
        "torch.einsum('ii', torch.randn(4, 4))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.8364)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CelcEpWqBrFB",
        "outputId": "74e0f21e-d870-4da6-ef1c-dfabf3f03c46"
      },
      "source": [
        "# diagonal\n",
        "torch.einsum('ii->i', torch.randn(4, 4))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7342,  0.2111,  0.1528, -0.3827])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hhXmfd2Btjw",
        "outputId": "765cc782-0bbf-490d-887c-93fc39fa63be"
      },
      "source": [
        "# outer product\n",
        "x = torch.randn(5)\n",
        "y = torch.randn(4)\n",
        "torch.einsum('i,j->ij', x, y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6560,  0.6210, -0.3489, -0.6460],\n",
              "        [ 0.4080,  0.3863, -0.2170, -0.4018],\n",
              "        [ 0.0282,  0.0267, -0.0150, -0.0278],\n",
              "        [-0.3338, -0.3160,  0.1775,  0.3287],\n",
              "        [ 1.0032,  0.9498, -0.5335, -0.9880]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Go9tVrBxX8",
        "outputId": "0df02aa4-1b77-45f2-9424-ae25c42258b8"
      },
      "source": [
        "# batch matrix multiplication\n",
        "As = torch.randn(3,2,5)\n",
        "Bs = torch.randn(3,5,4)\n",
        "torch.einsum('bij,bjk->bik', As, Bs)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-2.5163, -1.0991,  4.3671,  0.7771],\n",
              "         [-0.4865, -0.7334,  2.5397,  1.3406]],\n",
              "\n",
              "        [[ 2.0850,  0.5988,  2.4922,  2.7068],\n",
              "         [-1.0223,  1.0416,  0.3803, -1.3615]],\n",
              "\n",
              "        [[ 0.1737,  0.3008,  0.1883,  0.7262],\n",
              "         [-1.5035, -2.5971,  0.5111, -1.6418]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHBBXTAoBz8M",
        "outputId": "161fd568-5d9c-4f72-c147-0c8d9d62d7d1"
      },
      "source": [
        "# batch permute\n",
        "A = torch.randn(2, 3, 4, 5)\n",
        "torch.einsum('...ij->...ji', A).shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TjiWrhIB2bV",
        "outputId": "04780c57-33c6-4142-88e1-dcd456d60bd1"
      },
      "source": [
        "# equivalent to torch.nn.functional.bilinear\n",
        "A = torch.randn(3,5,4)\n",
        "l = torch.randn(2,5)\n",
        "r = torch.randn(2,4)\n",
        "torch.einsum('bn,anm,bm->ba', l, A, r)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4313,  0.3073,  1.1945],\n",
              "        [ 8.5409, -2.6836, -2.5755]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwG1kP1aB5ew",
        "outputId": "ee7c6ac2-00fb-406d-9ad8-7ba3e59d5ab8"
      },
      "source": [
        "#### atleast_1d\n",
        "\n",
        "x = torch.randn(2)\n",
        "print(x)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.3830, -0.0910])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exeur9bCB6uh",
        "outputId": "fc3e0a15-08d3-454e-92cd-9817eed33c67"
      },
      "source": [
        "torch.atleast_1d(x)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.3830, -0.0910])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-QwN2whCAI1",
        "outputId": "2e7315cb-dce3-4c44-ef65-98095ea65d6d"
      },
      "source": [
        "x = torch.tensor(1.)\n",
        "torch.atleast_1d(x)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erjai4DpCAAS",
        "outputId": "abf33588-bfec-4f12-dd5a-35cb58684f15"
      },
      "source": [
        "x = torch.tensor(0.5)\n",
        "y = torch.tensor(1.)\n",
        "torch.atleast_1d((x,y))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.5000]), tensor([1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0UmfupRCDhN",
        "outputId": "a03fc3ce-cf69-4033-c5ae-5268e5d54d22"
      },
      "source": [
        "#### bucketize\n",
        "\n",
        "boundaries = torch.tensor([1, 3, 5, 7, 9])\n",
        "print(boundaries)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 5, 7, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU5XqfwMCHNA",
        "outputId": "b4fdf9ba-de82-45e6-c0bd-a0dc54aa3ece"
      },
      "source": [
        "v = torch.tensor([[3, 6, 9], [3, 6, 9]])\n",
        "torch.bucketize(v, boundaries)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3, 4],\n",
              "        [1, 3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01xc2JN6CJwK",
        "outputId": "70785518-86ef-4048-873a-10df449f4486"
      },
      "source": [
        "torch.bucketize(v, boundaries, right=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 3, 5],\n",
              "        [2, 3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQHA9ZMrCVZd"
      },
      "source": [
        "# 🦆 Math operations - BLAS and LAPACK Operations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2fjFgjwCchP",
        "outputId": "da36d53d-6b02-4bd7-c39a-9cfbc368a822"
      },
      "source": [
        "M = torch.randn(2, 3)\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.addmm(M, mat1, mat2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6278, -0.6869, -0.3568],\n",
              "        [ 0.5679, -0.8697, -0.4615]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVwjLVdSCgcS",
        "outputId": "b532672a-5d6b-4419-d196-86a4e568e0c6"
      },
      "source": [
        "a = torch.eye(10)\n",
        "torch.matrix_rank(a)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.matrix_rank is deprecated in favor of torch.linalg.matrix_rankand will be removed in a future PyTorch release. The parameter 'symmetric' was renamed in torch.linalg.matrix_rank to 'hermitian'. (Triggered internally at  /pytorch/aten/src/ATen/native/LinearAlgebra.cpp:438.)\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFp638shCide",
        "outputId": "f173dddb-d9ec-472f-f1c1-94c09e708627"
      },
      "source": [
        "b = torch.eye(10)\n",
        "b[0, 0] = 0\n",
        "torch.matrix_rank(b)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlReTRCfCmZu",
        "outputId": "1b8535e7-e326-46cd-cb2d-80e02ade5c4d"
      },
      "source": [
        "a = torch.tensor([[12., -51, 4],\n",
        "                  [6, 167, -68],\n",
        "                  [-4, 24, -41]])\n",
        "q, r = torch.qr(a)\n",
        "torch.mm(q, r).round()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
            "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
            "Q, R = torch.qr(A, some)\n",
            "should be replaced with\n",
            "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:1940.)\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 12., -51.,   4.],\n",
              "        [  6., 167., -68.],\n",
              "        [ -4.,  24., -41.]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cye3e5pOCrwN",
        "outputId": "c3eaacc6-943c-4fa5-b9bd-cd0c498fac6f"
      },
      "source": [
        "torch.allclose(torch.matmul(q, r), a)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTqfU-CMCuKT",
        "outputId": "d015dae7-cca0-4fbc-ecd4-d5cf47307e8a"
      },
      "source": [
        "#### addmv\n",
        "\n",
        "M = torch.randn(2)\n",
        "mat = torch.randn(2, 3)\n",
        "vec = torch.randn(3)\n",
        "torch.addmv(M, mat, vec)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.5329, -1.5686])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DnRqdZjCxyz",
        "outputId": "166c3455-6b41-4629-bbff-e6990b6b3263"
      },
      "source": [
        "#### baddbmm\n",
        "\n",
        "M = torch.randn(10, 3, 5)\n",
        "batch1 = torch.randn(10, 3, 4)\n",
        "batch2 = torch.randn(10, 4, 5)\n",
        "torch.baddbmm(M, batch1, batch2).size()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biZeKU4RC_LM"
      },
      "source": [
        "##### torch.nn Linear Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq7xVPtHDIV4",
        "outputId": "3d87a017-2a2d-4fc6-e549-6dd8ec3f6b89"
      },
      "source": [
        "from torch import nn\n",
        "X = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "# 크기 변환 \n",
        "X = torch.nn.Linear(2,5)\n",
        "\n",
        "X = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# Identity\n",
        "temp = nn.Identity(X)\n",
        "print(temp(X).size())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_XQQCjqDr_R"
      },
      "source": [
        "```python\n",
        "😮\n",
        "Linear : 데이터를 선형 변환\n",
        "LazyLinear : 첫 번째 호출이 완료된 후 초기화되고 Linear 적용.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBeitZQBD6fy"
      },
      "source": [
        "##### nn.Module 모델 제작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aKTVdCQEOu6",
        "outputId": "18e36978-85b8-4c24-e12b-5e6548b1e562"
      },
      "source": [
        "# Add with nn.Module\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Add, self).__init__()\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        return x1 + x2\n",
        "\n",
        "x1 = torch.tensor([1])\n",
        "x2 = torch.tensor([2])\n",
        "\n",
        "add = Add()\n",
        "output = add(x1, x2)\n",
        "print(output)\n",
        "\n",
        "if output == 3:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3])\n",
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI2pjJWGEfDt",
        "outputId": "61aef202-ab09-4fee-bd40-0fcaf9d6b0bf"
      },
      "source": [
        "# torch.nn.Sequential로 모듈 묶기 (순차 실행)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "calculator = nn.Sequential(\n",
        "    Add(3),\n",
        "    Add(2),\n",
        "    Add(5)\n",
        ")\n",
        "\n",
        "x = torch.tensor([1])\n",
        "\n",
        "output = calculator(x)\n",
        "\n",
        "if output == 11:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SupKnR7Ee_Y",
        "outputId": "794887ba-6ee8-4918-b1cb-883017d8b621"
      },
      "source": [
        "# torch.nn.ModuleList로 모듈 묶기 (not 순차 실행. pikking.)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # y = ((x + 3) + 2) + 5\n",
        "        for i, add in enumerate(self.add_list):\n",
        "            x = x+add(0)\n",
        "        return x\n",
        "\n",
        "x = torch.tensor([1])\n",
        "\n",
        "calculator = Calculator()\n",
        "output = calculator(x)\n",
        "\n",
        "if output == 11:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhcIIxhaFLaS",
        "outputId": "858ab414-da98-4d72-cade-4ff94732a83c"
      },
      "source": [
        "# torch.nn.ModuleDict로 모듈 묶기\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_dict = nn.ModuleDict({'add2': Add(2),\n",
        "                                       'add3': Add(3),\n",
        "                                       'add5': Add(5)})\n",
        "\n",
        "    def forward(self, x):\n",
        "        # y = ((x + 3) + 2) + 5\n",
        "        for key in self.add_dict.keys():\n",
        "            x += self.add_dict[key](0)\n",
        "        return x\n",
        "\n",
        "x = torch.tensor([1])\n",
        "\n",
        "calculator = Calculator()\n",
        "output = calculator(x)\n",
        "\n",
        "if output == 11:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLPj598TFd3Z",
        "outputId": "4601a2fd-d19f-4995-cad6-f6ce6191a1c4"
      },
      "source": [
        "# Python List vs PyTorch ModuleList\n",
        "\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "\n",
        "class PythonList(nn.Module):\n",
        "    \"\"\"Python List\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Python List\n",
        "        self.add_list = [Add(2), Add(3), Add(5)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.add_list[1](x)\n",
        "        x = self.add_list[0](x)\n",
        "        x = self.add_list[2](x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class PyTorchList(nn.Module):\n",
        "    \"\"\"PyTorch List\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Pytorch ModuleList\n",
        "        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.add_list[1](x)\n",
        "        x = self.add_list[0](x)\n",
        "        x = self.add_list[2](x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "x = torch.tensor([1])\n",
        "\n",
        "python_list = PythonList()\n",
        "pytorch_list = PyTorchList()\n",
        "\n",
        "print(python_list(x), pytorch_list(x))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11]) tensor([11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAzOoagBFsIh",
        "outputId": "e5336772-72e0-4448-df71-f227a674da9f"
      },
      "source": [
        "# Python List로 모아놓은 모듈들은 사라졌다.\n",
        "python_list"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonList()"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGh6kTOjFyKP",
        "outputId": "591f8ba6-5ac0-42c2-c3e3-77c8668b7e1d"
      },
      "source": [
        "# 반면 PyTorch로 모아놓은 모듈들은 남아있다.\n",
        "pytorch_list"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PyTorchList(\n",
              "  (add_list): ModuleList(\n",
              "    (0): Add()\n",
              "    (1): Add()\n",
              "    (2): Add()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB-3Jfc8F_fB"
      },
      "source": [
        "```python\n",
        "😮\n",
        "Model은 nn.Module을 상속하여 정의.\n",
        "단순 list로 저장 시, 레이어 인식이 안될 수 있음.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC9u7oIDGLWk",
        "outputId": "560901b3-a7b6-4cfb-b18c-3d9241715391"
      },
      "source": [
        "# using condition statement\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "class Sub(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.value\n",
        "\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self, cal_type):\n",
        "        super().__init__()\n",
        "        self.cal_type = cal_type\n",
        "        self.add = Add(3)\n",
        "        self.sub = Sub(3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # \"add\" -> y = x + 3\n",
        "        # \"sub\" -> y = x - 3\n",
        "        # \"add\", \"sub\"가 아닌 다른 문자열이 입력되면 ValueError\n",
        "        if self.cal_type == \"add\":\n",
        "            x = self.add(x)\n",
        "        elif self.cal_type == \"sub\":\n",
        "            x = self.sub(x)\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "        return x\n",
        "\n",
        "x = torch.tensor([5])\n",
        "\n",
        "try:\n",
        "    calculator = Calculator(\"none\")\n",
        "    output = calculator(x)\n",
        "\n",
        "    print(\"🦆 잘못된 문자열 입력에는 에러를 발생시키세요!!\")\n",
        "except ValueError:\n",
        "    calculator = Calculator(\"add\")\n",
        "    add_output = calculator(x)\n",
        "\n",
        "    calculator = Calculator(\"sub\")\n",
        "    sub_output = calculator(x)\n",
        "    \n",
        "    if add_output == 8 and sub_output == 2:\n",
        "        print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "    else:\n",
        "        print(\"🦆 다시 도전해봐요!\")\n",
        "except:\n",
        "    print(\"🦆 ValueError를 발생시키세요!!\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJD_sQEBGltJ",
        "outputId": "eeb9e491-5feb-4002-9177-1a61f5e0e4d1"
      },
      "source": [
        "# 모듈의 흐름을 느껴봐\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function A Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function A started\")\n",
        "        print(f\"        Function A done\")\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function B Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function B started\")\n",
        "        print(f\"        Function B done\")\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function C Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function C started\")\n",
        "        print(f\"        Function C done\")\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function D Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function D started\")\n",
        "        print(f\"        Function D done\")\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A()\n",
        "        self.b = Function_B()\n",
        "\n",
        "        print(f\"    Layer AB Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"    Layer AB started\")\n",
        "        self.a(x)\n",
        "        self.b(x)\n",
        "        print(f\"    Layer AB done\")\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C()\n",
        "        self.d = Function_D()\n",
        "\n",
        "        print(f\"    Layer CD Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"    Layer CD started\")\n",
        "        self.c(x)\n",
        "        self.d(x)\n",
        "        print(f\"    Layer CD done\")\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "        print(f\"Model ABCD Initialized\\n\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"Model ABCD started\")\n",
        "        self.ab(x)\n",
        "        self.cd(x)\n",
        "        print(f\"Model ABCD done\\n\")\n",
        "\n",
        "\n",
        "x = torch.tensor([7])\n",
        "\n",
        "model = Model()\n",
        "model(x)\n",
        "\n",
        "print(\"🎉🎉🎉 모든 딥러닝 모델은 이처럼 Module들이 쌓이고 쌓여서 만들어집니다! 🎉🎉🎉\")\n",
        "print(\"🎉🎉🎉 흐름을 느껴보시고 이 흐름이 이해가 되신 분은 다음으로 가시면 됩니다! 🎉🎉\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Function A Initialized\n",
            "        Function B Initialized\n",
            "    Layer AB Initialized\n",
            "        Function C Initialized\n",
            "        Function D Initialized\n",
            "    Layer CD Initialized\n",
            "Model ABCD Initialized\n",
            "\n",
            "Model ABCD started\n",
            "    Layer AB started\n",
            "        Function A started\n",
            "        Function A done\n",
            "        Function B started\n",
            "        Function B done\n",
            "    Layer AB done\n",
            "    Layer CD started\n",
            "        Function C started\n",
            "        Function C done\n",
            "        Function D started\n",
            "        Function D done\n",
            "    Layer CD done\n",
            "Model ABCD done\n",
            "\n",
            "🎉🎉🎉 모든 딥러닝 모델은 이처럼 Module들이 쌓이고 쌓여서 만들어집니다! 🎉🎉🎉\n",
            "🎉🎉🎉 흐름을 느껴보시고 이 흐름이 이해가 되신 분은 다음으로 가시면 됩니다! 🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfkoZcuVG0Wl",
        "outputId": "acb45fae-32a3-4edd-e960-483cfdd6e358"
      },
      "source": [
        "# Parameter\n",
        "# Tensor 이용시와 달리 Parameter Class를 이용해 생성시,\n",
        "# output tensor에 gradient function이 추가.\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.W = Parameter(torch.ones((out_features, in_features)))\n",
        "        self.b =Parameter(torch.ones(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.addmm(self.b, x, self.W.T)\n",
        "        return output\n",
        "\n",
        "x = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "linear = Linear(2, 3)\n",
        "output = linear(x)\n",
        "\n",
        "if torch.all(output == torch.Tensor([[4, 4, 4],\n",
        "                                     [8, 8, 8]])):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADRNYTACHZrj",
        "outputId": "aaeb61ab-cd7d-458b-98f9-84207a06cc2d"
      },
      "source": [
        "# buffer\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.parameter = Parameter(torch.Tensor([7]))\n",
        "        self.tensor = torch.Tensor([7])\n",
        "        self.register_buffer('buffer', torch.Tensor([7]))\n",
        "\n",
        "model = Model()\n",
        "\n",
        "try:\n",
        "    buffer = model.get_buffer('buffer')\n",
        "    if buffer == 7:\n",
        "        print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\\n\")\n",
        "        print(\"🎉 이제 buffer에 등록된 tensor는 모델이 저장될 때 같이 저장될거예요! 🎉\")\n",
        "        print(model.state_dict())\n",
        "    else:\n",
        "        print(\"🦆 다시 도전해봐요!\")\n",
        "except:\n",
        "    print(\"🦆 다시 도전해봐요!\")\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n",
            "\n",
            "🎉 이제 buffer에 등록된 tensor는 모델이 저장될 때 같이 저장될거예요! 🎉\n",
            "OrderedDict([('parameter', tensor([7.])), ('buffer', tensor([7.]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNj-8UgCHp5N"
      },
      "source": [
        "```python\n",
        "😮\n",
        "- \"Tensor\"\n",
        "    - ❌ gradient 계산\n",
        "    - ❌ 값 업데이트\n",
        "    - ❌ 모델 저장시 값 저장\n",
        "- \"Parameter\"\n",
        "    - ✅ gradient 계산\n",
        "    - ✅ 값 업데이트\n",
        "    - ✅ 모델 저장시 값 저장\n",
        "- \"Buffer\"\n",
        "    - ❌ gradient 계산\n",
        "    - ❌ 값 업데이트\n",
        "    - ✅ 모델 저장시 값 저장\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkLLXF9CH1zi"
      },
      "source": [
        "##### nn.Module 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qzc8lClIbZ_",
        "outputId": "58092072-9961-40f1-d919-5aa949829501"
      },
      "source": [
        "# 자신에게 속한 모든 submodule을 표시\n",
        "for name, module in model.named_modules():\n",
        "    print(f\"[ Name ] : {name}\\n[ Module ]\\n{module}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ Name ] : \n",
            "[ Module ]\n",
            "Model()\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsHdcg55IkV1"
      },
      "source": [
        "# 한 단계 아래의 submodule만 표시\n",
        "for name, child in model.named_children():\n",
        "    print(f\"[ Name ] : {name}\\n[ Children ]\\n{child}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuanxa3lI6vN",
        "outputId": "ede98812-d5ca-4559-d0cb-7406edbae5cc"
      },
      "source": [
        "# 파라미터 목록 표시\n",
        "for name, parameter in model.named_parameters():\n",
        "    print(f\"[ Name ] : {name}\\n[ Parameter ]\\n{parameter}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ Name ] : parameter\n",
            "[ Parameter ]\n",
            "Parameter containing:\n",
            "tensor([7.], requires_grad=True)\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDXMafDRJDN_",
        "outputId": "df97f9ce-651f-4020-820b-31f484553212"
      },
      "source": [
        "# buffer 표시\n",
        "for name, buffer in model.named_buffers():\n",
        "    print(f\"[ Name ] : {name}\\n[ Buffer ] : {buffer}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ Name ] : buffer\n",
            "[ Buffer ] : tensor([7.])\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAhpYAjEJe8X",
        "outputId": "f3ae09ff-842f-4bd5-8536-070f5f7e159f"
      },
      "source": [
        "# 부덕 모델\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "# 하지만 아래 과제를 진행하기 전에 아래 코드를 보면서 최대한 이해해보세요!\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * 2\n",
        "        return x\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([10]))\n",
        "        self.W2 = Parameter(torch.Tensor([2]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / self.W1\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * self.duck\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([3]))\n",
        "        self.W2 = Parameter(torch.Tensor([5]))\n",
        "        self.c = Function_C()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.W1\n",
        "        x = self.c(x)\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('duck')\n",
        "        self.b = Function_B()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x) / 5\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C()\n",
        "        self.d = Function_D()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x) + 1\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "x = torch.tensor([7])\n",
        "\n",
        "model = Model()\n",
        "model(x)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.5720], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku43Wxf_JrFd"
      },
      "source": [
        "# In Function_D, Function_C 참조 제거\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([3]))\n",
        "        self.W2 = Parameter(torch.Tensor([5]))\n",
        "        # self.c = Function_C()\n",
        "        self.register_buffer('modify_c', torch.Tensor([7]), persistent = True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.W1\n",
        "        # x = self.c(x)\n",
        "        x *= self.modify_c\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evoV-ieTKDZr"
      },
      "source": [
        "# In Function_A, 출력 수정\n",
        "\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * 2\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) :\n",
        "        return f'name={self.name}'"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt9xk97IKYii"
      },
      "source": [
        "##### nn.Module hook & apply"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgAhEar-Keh5",
        "outputId": "32af582a-45b6-41f6-acd7-6f8d93ad99d1"
      },
      "source": [
        "# What is hook?\n",
        "\n",
        "def program_A(x):\n",
        "    print('program A processing!')\n",
        "    return x + 3\n",
        "\n",
        "def program_B(x):\n",
        "    print('program B processing!')\n",
        "    return x - 3\n",
        "\n",
        "class Package(object):\n",
        "    \"\"\"프로그램 A와 B를 묶어놓은 패키지 코드\"\"\"\n",
        "    def __init__(self):\n",
        "        self.programs = [program_A, program_B]\n",
        "        self.hooks = []\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for program in self.programs:\n",
        "            x = program(x)\n",
        "\n",
        "            # Package를 사용하는 사람이 자신만의 custom program을\n",
        "            # 등록할 수 있도록 미리 만들어놓은 인터페이스 hook\n",
        "            if self.hooks:\n",
        "                for hook in self.hooks:\n",
        "                    output = hook(x)\n",
        "\n",
        "                    # return 값이 있는 hook의 경우에만 x를 업데이트 한다\n",
        "                    if output:\n",
        "                        x = output\n",
        "\n",
        "        return x\n",
        "\n",
        "# 패키지 생성\n",
        "package = Package()\n",
        "\n",
        "# 패키지 실행\n",
        "input = 3\n",
        "output = package(input)\n",
        "\n",
        "# 패키지 결과\n",
        "print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program A processing!\n",
            "program B processing!\n",
            "Package Process Result! [ input 3 ] [ output 3 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZFaCbXQLAUi",
        "outputId": "ce7d634c-a714-4728-f010-bc1058ac7457"
      },
      "source": [
        "# forward hook 전파 과정\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() \n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = torch.add(x1, x2)\n",
        "\n",
        "        return output\n",
        "\n",
        "add = Add()\n",
        "\n",
        "answer = []\n",
        "\n",
        "def pre_hook(module, input):\n",
        "    x1, x2 = input\n",
        "    answer.append(x1)\n",
        "    answer.append(x2)\n",
        "add.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "def hook(module, input, output):\n",
        "    answer.append(output)\n",
        "add.register_forward_hook(hook)\n",
        "\n",
        "x1 = torch.rand(1)\n",
        "x2 = torch.rand(1)\n",
        "\n",
        "output = add(x1, x2)\n",
        "\n",
        "if answer == [x1, x2, output]:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svfN9c7SLSA0",
        "outputId": "82bd87d7-1660-408f-afe1-c26cbc39cf61"
      },
      "source": [
        "# 전파중 값 수정 가능\n",
        "\n",
        "def hook(module, input, output):\n",
        "    output += 5\n",
        "    return output\n",
        "add.register_forward_hook(hook)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f60ceea4490>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4cfi--WLf5g",
        "outputId": "e472a7d8-5e9c-4689-a470-ac708ea221f5"
      },
      "source": [
        "# backward hook\n",
        "# forward hook은 module에만 적용할 수 있으나,\n",
        "# backward hook은 tensor, module 모두 적용 가능\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W = Parameter(torch.Tensor([5]))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = x1 * x2\n",
        "        output = output * self.W\n",
        "\n",
        "        return output\n",
        "\n",
        "model = Model()\n",
        "\n",
        "answer = []\n",
        "\n",
        "def module_hook(module, grad_input, grad_output):\n",
        "    answer.append(x2 * grad_input[0])\n",
        "    answer.append(x1 * grad_input[0])\n",
        "    answer.append(grad_output[0])\n",
        "model.register_backward_hook(module_hook)\n",
        "\n",
        "x1 = torch.rand(1, requires_grad=True)\n",
        "x2 = torch.rand(1, requires_grad=True)\n",
        "\n",
        "output = model(x1, x2)\n",
        "output.retain_grad()\n",
        "output.backward()\n",
        "\n",
        "if answer == [x1.grad, x2.grad, output.grad]:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzvIjwarMCPa",
        "outputId": "3be07dbd-63fc-4d5c-84e7-6ac2de8ed594"
      },
      "source": [
        "# tensor 단위 backward hook\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W = Parameter(torch.Tensor([5]))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = x1 * x2\n",
        "        output = output * self.W\n",
        "\n",
        "        return output\n",
        "\n",
        "model = Model()\n",
        "\n",
        "answer = []\n",
        "\n",
        "def tensor_hook(grad):\n",
        "    answer.append(grad)\n",
        "list(model.parameters())[0].register_hook(tensor_hook)\n",
        "\n",
        "x1 = torch.rand(1, requires_grad=True)\n",
        "x2 = torch.rand(1, requires_grad=True)\n",
        "\n",
        "output = model(x1, x2)\n",
        "output.backward()\n",
        "\n",
        "if answer == [model.W.grad]:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOTK5YygMNfd",
        "outputId": "cf3fd9a3-a8d5-481c-8d80-48ee9f4d58cc"
      },
      "source": [
        "# 마찬가지로 전파 값 수정 가능\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W = Parameter(torch.Tensor([5]))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = x1 * x2\n",
        "        output = output * self.W\n",
        "\n",
        "        return output\n",
        "\n",
        "model = Model()\n",
        "\n",
        "def module_hook(module, grad_input, grad_output):\n",
        "    grad_input = list(grad_input)\n",
        "    grad_input[0] = 1/(x1+x2)\n",
        "    return tuple(grad_input)\n",
        "model.register_backward_hook(module_hook)\n",
        "\n",
        "x1 = torch.rand(1, requires_grad=True)\n",
        "x2 = torch.rand(1, requires_grad=True)\n",
        "\n",
        "output = model(x1, x2)\n",
        "output.backward()\n",
        "\n",
        "if x1.grad + x2.grad == 1:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRNjp8MtMcm6",
        "outputId": "6f89bae9-bd2e-4dd8-d1c4-11db0be1bfe1"
      },
      "source": [
        "# apply example\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "@torch.no_grad()\n",
        "def init_weights(m):\n",
        "    print(m)\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.fill_(1.0)\n",
        "        print(m.weight)\n",
        "\n",
        "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
        "net.apply(init_weights)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=2, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "Linear(in_features=2, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
            "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_RvPKgFM2d1",
        "outputId": "56780038-b081-4d02-a1ff-c35576b7ad74"
      },
      "source": [
        "# 수정을 위한 부덕 모델\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "# 하지만 아래 과제를 진행하기 전에 아래 코드를 보면서 최대한 이해해보세요!\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.W\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.W\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.W\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / self.W\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('plus')\n",
        "        self.b = Function_B('substract')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x)\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C('multiply')\n",
        "        self.d = Function_D('divide')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Model()\n",
        "\n",
        "def print_module(module):\n",
        "    print(module)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "returned_module = model.apply(print_module)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function_A()\n",
            "------------------------------\n",
            "Function_B()\n",
            "------------------------------\n",
            "Layer_AB(\n",
            "  (a): Function_A()\n",
            "  (b): Function_B()\n",
            ")\n",
            "------------------------------\n",
            "Function_C()\n",
            "------------------------------\n",
            "Function_D()\n",
            "------------------------------\n",
            "Layer_CD(\n",
            "  (c): Function_C()\n",
            "  (d): Function_D()\n",
            ")\n",
            "------------------------------\n",
            "Model(\n",
            "  (ab): Layer_AB(\n",
            "    (a): Function_A()\n",
            "    (b): Function_B()\n",
            "  )\n",
            "  (cd): Layer_CD(\n",
            "    (c): Function_C()\n",
            "    (d): Function_D()\n",
            "  )\n",
            ")\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgNxpA77NJDI",
        "outputId": "05520cb9-1d16-447c-bffe-7ae1459b97b8"
      },
      "source": [
        "# 가중치 초기화 (Weight Initialization)\n",
        "\n",
        "def weight_initialization(module):\n",
        "    module_name = module.__class__.__name__\n",
        "    if module_name.find('Function') != -1 :\n",
        "        module.W.data.fill_(1.0)\n",
        "returned_module = model.apply(weight_initialization)\n",
        "\n",
        "x = torch.rand(1)\n",
        "\n",
        "output = model(x)\n",
        "\n",
        "if torch.isclose(output, x):\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AoU0TGOSP0-",
        "outputId": "b442b3ea-fc6e-4f44-d39a-5ae5098152a2"
      },
      "source": [
        "# apply - repr 수정\n",
        "\n",
        "model = Model()\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "def function_repr(self):\n",
        "    return f'name={self.name}'\n",
        "\n",
        "def add_repr(module):\n",
        "    module_name = module.__class__.__name__\n",
        "    if module_name.find('Function') != -1:\n",
        "        module.extra_repr = partial(function_repr, module)\n",
        "returned_module = model.apply(add_repr)\n",
        "\n",
        "model_repr = repr(model)\n",
        "\n",
        "print(\"모델 출력 결과\")\n",
        "print(\"-\" * 30)\n",
        "print(model_repr)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "answer = \"Model(\\n  (ab): Layer_AB(\\n    (a): Function_A(name=plus)\\n    (b): Function_B(name=substract)\\n  )\\n  (cd): Layer_CD(\\n    (c): Function_C(name=multiply)\\n    (d): Function_D(name=divide)\\n  )\\n)\"\n",
        "\n",
        "if model_repr == answer:\n",
        "    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "    print(\"🦆 너무 고마워요 꽉꽉!\")\n",
        "else:\n",
        "    print(\"🦆 다시 도전해봐요!\")\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 출력 결과\n",
            "------------------------------\n",
            "Model(\n",
            "  (ab): Layer_AB(\n",
            "    (a): Function_A(name=plus)\n",
            "    (b): Function_B(name=substract)\n",
            "  )\n",
            "  (cd): Layer_CD(\n",
            "    (c): Function_C(name=multiply)\n",
            "    (d): Function_D(name=divide)\n",
            "  )\n",
            ")\n",
            "------------------------------\n",
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n",
            "🦆 너무 고마워요 꽉꽉!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IGT5NliSenc"
      },
      "source": [
        "# apply - Function 수정\n",
        "\n",
        "model = Model()\n",
        "\n",
        "def add_bias(module):\n",
        "    module_name = module.__class__.__name__\n",
        "    if module_name.split('_')[0] == \"Function\":\n",
        "        module.b = Parameter(torch.rand(1, 2))\n",
        "\n",
        "def weight_initialization(module):\n",
        "    module_name = module.__class__.__name__\n",
        "\n",
        "    if module_name.split('_')[0] == \"Function\":\n",
        "        module.W.data.fill_(1.)\n",
        "        module.b.data.fill_(1.)\n",
        "\n",
        "# X @ W + b\n",
        "def linear_transformation(module):\n",
        "    def linear_forward(self, x):\n",
        "        return x @ self.W.T + self.b\n",
        "    module_name = module.__class__.__name__\n",
        "\n",
        "    if module_name.split('_')[0] == \"Function\":\n",
        "        module.forward = partial(linear_forward, module)\n",
        "\n",
        "returned_module = model.apply(add_bias)\n",
        "returned_module = model.apply(weight_initialization)\n",
        "returned_module = model.apply(linear_transformation)"
      ],
      "execution_count": 81,
      "outputs": []
    }
  ]
}